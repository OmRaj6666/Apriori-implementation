{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4418ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Number of transactions: 20\n",
      "Number of unique items: 12\n",
      "\n",
      "Top 10 Frequent Itemsets by Support:\n",
      "    support         itemsets  itemsets_len\n",
      "1      0.70          (bread)             1\n",
      "6      0.60           (milk)             1\n",
      "5      0.55           (eggs)             1\n",
      "13     0.40    (eggs, bread)             2\n",
      "14     0.35    (milk, bread)             2\n",
      "2      0.30         (butter)             1\n",
      "17     0.30     (eggs, milk)             2\n",
      "11     0.25  (butter, bread)             2\n",
      "0      0.20          (bacon)             1\n",
      "10     0.20    (eggs, bacon)             2\n",
      "\n",
      "Top 10 Association Rules by Lift:\n",
      "      antecedents    consequents  support  confidence      lift\n",
      "8         (bacon)  (eggs, bread)     0.15    0.750000  1.875000\n",
      "1         (bacon)         (eggs)     0.20    1.000000  1.818182\n",
      "7  (bacon, bread)         (eggs)     0.15    1.000000  1.818182\n",
      "5        (yogurt)         (milk)     0.15    1.000000  1.666667\n",
      "3        (cheese)        (bread)     0.15    1.000000  1.428571\n",
      "2        (butter)        (bread)     0.25    0.833333  1.190476\n",
      "0         (bacon)        (bread)     0.15    0.750000  1.071429\n",
      "6   (eggs, bacon)        (bread)     0.15    0.750000  1.071429\n",
      "4          (eggs)        (bread)     0.40    0.727273  1.038961\n",
      "9    (eggs, milk)        (bread)     0.20    0.666667  0.952381\n",
      "\n",
      "=== BUSINESS INSIGHTS ===\n",
      "\n",
      "Most Commonly Purchased Products:\n",
      "- bread: appears in 70.0% of transactions\n",
      "- milk: appears in 60.0% of transactions\n",
      "- eggs: appears in 55.0% of transactions\n",
      "- butter: appears in 30.0% of transactions\n",
      "- bacon: appears in 20.0% of transactions\n",
      "- cheese: appears in 15.0% of transactions\n",
      "- coffee: appears in 15.0% of transactions\n",
      "- sugar: appears in 15.0% of transactions\n",
      "- yogurt: appears in 15.0% of transactions\n",
      "\n",
      "Strongest Product Associations (by lift):\n",
      "- If customer buys bacon, they are 1.87x more likely to buy eggs, bread\n",
      "  (Support: 15.0%, Confidence: 75.0%)\n",
      "- If customer buys bacon, they are 1.82x more likely to buy eggs\n",
      "  (Support: 20.0%, Confidence: 100.0%)\n",
      "- If customer buys bacon, bread, they are 1.82x more likely to buy eggs\n",
      "  (Support: 15.0%, Confidence: 100.0%)\n",
      "- If customer buys yogurt, they are 1.67x more likely to buy milk\n",
      "  (Support: 15.0%, Confidence: 100.0%)\n",
      "- If customer buys cheese, they are 1.43x more likely to buy bread\n",
      "  (Support: 15.0%, Confidence: 100.0%)\n",
      "\n",
      "Products Most Often Bought Together (by support):\n",
      "- eggs and bread appear together in 40.0% of transactions\n",
      "  (Confidence: 72.7%, Lift: 1.04)\n",
      "- butter and bread appear together in 25.0% of transactions\n",
      "  (Confidence: 83.3%, Lift: 1.19)\n",
      "- bacon and eggs appear together in 20.0% of transactions\n",
      "  (Confidence: 100.0%, Lift: 1.82)\n",
      "- eggs, milk and bread appear together in 20.0% of transactions\n",
      "  (Confidence: 66.7%, Lift: 0.95)\n",
      "- bacon and bread appear together in 15.0% of transactions\n",
      "  (Confidence: 75.0%, Lift: 1.07)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample transaction data (in a real scenario, this would be loaded from a CSV/database)\n",
    "transactions = [\n",
    "    ['bread', 'milk', 'eggs'],\n",
    "    ['bread', 'butter', 'jam'],\n",
    "    ['milk', 'butter', 'eggs', 'yogurt'],\n",
    "    ['bread', 'milk', 'butter', 'eggs'],\n",
    "    ['bread', 'milk', 'butter'],\n",
    "    ['eggs', 'bacon', 'bread'],\n",
    "    ['milk', 'eggs', 'cereal', 'fruit'],\n",
    "    ['bread', 'eggs', 'bacon'],\n",
    "    ['bread', 'milk', 'eggs', 'yogurt'],\n",
    "    ['coffee', 'sugar', 'milk'],\n",
    "    ['coffee', 'bread', 'butter'],\n",
    "    ['bread', 'eggs', 'milk', 'cheese'],\n",
    "    ['milk', 'yogurt', 'fruit'],\n",
    "    ['bread', 'coffee', 'sugar'],\n",
    "    ['eggs', 'bacon'],\n",
    "    ['bread', 'milk', 'cheese'],\n",
    "    ['bread', 'butter', 'eggs', 'bacon'],\n",
    "    ['cereal', 'milk', 'sugar'],\n",
    "    ['bread', 'jam', 'milk'],\n",
    "    ['bread', 'cheese', 'eggs']\n",
    "]\n",
    "\n",
    "# Function to convert transactions to one-hot encoded format\n",
    "def encode_transactions(transactions):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    return df\n",
    "\n",
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "def find_frequent_itemsets(df, min_support=0.1):\n",
    "    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    frequent_itemsets['itemsets_len'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Generate association rules from frequent itemsets\n",
    "def generate_rules(frequent_itemsets, min_threshold=0.5):\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_threshold)\n",
    "    return rules\n",
    "\n",
    "# Visualize the support of frequent itemsets\n",
    "def plot_support(frequent_itemsets):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Filter to itemsets with 1 or 2 items for better readability\n",
    "    plot_data = frequent_itemsets[frequent_itemsets['itemsets_len'] <= 2].copy()\n",
    "    \n",
    "    # Convert frozensets to strings for plotting\n",
    "    plot_data['itemsets_str'] = plot_data['itemsets'].apply(lambda x: ', '.join(list(x)))\n",
    "    \n",
    "    # Sort by support\n",
    "    plot_data = plot_data.sort_values('support', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    sns.barplot(x='support', y='itemsets_str', data=plot_data)\n",
    "    plt.title('Support of Frequent Itemsets')\n",
    "    plt.xlabel('Support')\n",
    "    plt.ylabel('Itemsets')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Visualize the association rules\n",
    "def plot_rules(rules):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Convert antecedents and consequents to strings\n",
    "    rules_plot = rules.copy()\n",
    "    rules_plot['antecedents_str'] = rules_plot['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "    rules_plot['consequents_str'] = rules_plot['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "    rules_plot['rule'] = rules_plot['antecedents_str'] + ' â†’ ' + rules_plot['consequents_str']\n",
    "    \n",
    "    # Sort by lift and select top 10 for visualization\n",
    "    rules_plot = rules_plot.sort_values('lift', ascending=False).head(10)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x='support', y='confidence', size='lift', \n",
    "                    sizes=(50, 400), data=rules_plot, alpha=0.7)\n",
    "    \n",
    "    # Add rule text as annotations\n",
    "    for i, row in rules_plot.iterrows():\n",
    "        plt.annotate(row['rule'], \n",
    "                    (row['support'], row['confidence']),\n",
    "                    xytext=(7, 0), \n",
    "                    textcoords='offset points',\n",
    "                    fontsize=8)\n",
    "    \n",
    "    plt.title('Association Rules: Support vs Confidence (size represents lift)')\n",
    "    plt.xlabel('Support')\n",
    "    plt.ylabel('Confidence')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Main analysis function\n",
    "def perform_market_basket_analysis(transactions, min_support=0.1, min_confidence=0.5):\n",
    "    # Encode transactions\n",
    "    df = encode_transactions(transactions)\n",
    "    \n",
    "    # Find frequent itemsets\n",
    "    frequent_itemsets = find_frequent_itemsets(df, min_support)\n",
    "    \n",
    "    # Generate rules\n",
    "    rules = generate_rules(frequent_itemsets, min_confidence)\n",
    "    \n",
    "    return df, frequent_itemsets, rules\n",
    "\n",
    "# Run the analysis\n",
    "df, frequent_itemsets, rules = perform_market_basket_analysis(\n",
    "    transactions, \n",
    "    min_support=0.15,  # Items appearing in at least 15% of transactions\n",
    "    min_confidence=0.6  # Rules with at least 60% confidence\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Number of transactions: {len(transactions)}\")\n",
    "print(f\"Number of unique items: {len(df.columns)}\")\n",
    "print(\"\\nTop 10 Frequent Itemsets by Support:\")\n",
    "print(frequent_itemsets.sort_values('support', ascending=False).head(10))\n",
    "print(\"\\nTop 10 Association Rules by Lift:\")\n",
    "print(rules.sort_values('lift', ascending=False).head(10)[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "\n",
    "# Calculate some basic business insights\n",
    "def extract_business_insights(rules, frequent_itemsets):\n",
    "    # Most commonly purchased products\n",
    "    single_items = frequent_itemsets[frequent_itemsets['itemsets_len'] == 1].sort_values('support', ascending=False)\n",
    "    \n",
    "    # Most valuable product associations (by lift)\n",
    "    top_associations = rules.sort_values('lift', ascending=False).head(5)\n",
    "    \n",
    "    # Products often bought together (by support)\n",
    "    products_together = rules.sort_values('support', ascending=False).head(5)\n",
    "    \n",
    "    return single_items, top_associations, products_together\n",
    "\n",
    "# Get insights\n",
    "single_items, top_associations, products_together = extract_business_insights(rules, frequent_itemsets)\n",
    "\n",
    "# Print insights\n",
    "print(\"\\n=== BUSINESS INSIGHTS ===\")\n",
    "print(\"\\nMost Commonly Purchased Products:\")\n",
    "for i, row in single_items.iterrows():\n",
    "    item = list(row['itemsets'])[0]\n",
    "    print(f\"- {item}: appears in {row['support']*100:.1f}% of transactions\")\n",
    "\n",
    "print(\"\\nStrongest Product Associations (by lift):\")\n",
    "for i, row in top_associations.iterrows():\n",
    "    antecedent = ', '.join(list(row['antecedents']))\n",
    "    consequent = ', '.join(list(row['consequents']))\n",
    "    print(f\"- If customer buys {antecedent}, they are {row['lift']:.2f}x more likely to buy {consequent}\")\n",
    "    print(f\"  (Support: {row['support']*100:.1f}%, Confidence: {row['confidence']*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nProducts Most Often Bought Together (by support):\")\n",
    "for i, row in products_together.iterrows():\n",
    "    antecedent = ', '.join(list(row['antecedents']))\n",
    "    consequent = ', '.join(list(row['consequents']))\n",
    "    print(f\"- {antecedent} and {consequent} appear together in {row['support']*100:.1f}% of transactions\")\n",
    "    print(f\"  (Confidence: {row['confidence']*100:.1f}%, Lift: {row['lift']:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
